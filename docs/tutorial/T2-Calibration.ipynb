{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T2 - Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models are simplifications of the real world, and quantities in the model (like the force of infection) represent the aggregation of many different factors. As a result, there can be uncertainty as to what value of the parameters most accurately reflects the real world - for instance, the population force of infection varies with the average number of contacts per person per day, but this quantity may not be well constrained. The first step in running a model is to improve estimates of the parameter values for a particular setting, using data from that setting. Typically, the model is started off at some point in the past (e.g. 2000), such that the initial compartment sizes correspond to the data in the simulation start year. The model is then run up to the current year, with the compartment sizes changing due to the model parameters. The model predictions can then be compared to the actual data for those same years. This allows model parameters to be adjusted to best match the existing data. These same parameters are then used for future projections.\n",
    "\n",
    "To see calibration in effect, consider the following simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import atomica as at\n",
    "P = at.Project(framework='assets/T2/t2_framework_1.xlsx',databook='assets/T2/t2_databook_1.xlsx', do_run=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we inspect the default calibration by running the model and plotting it along with the data. To plot the data, pass the project's data to the plotting function (in this case, `plot_series`) - this will automatically add scatter points to the plot based on the data in the databook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = P.run_sim()\n",
    "d = at.PlotData(result,project=P)\n",
    "at.plot_series(d, data=P.data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the number of susceptible people and infected people exactly match the data points in the simulation start year - as noted above, this is because the model is initialized from the data values in that year. There are some conditions under which the model won't exactly match the data in the initial year, such as if the initialization characteristics are overdetermined, but these situations are rare. \n",
    "\n",
    "We can see, however, that the model does not predict enough susceptible people in 2020. There could be many reasons for this, and determining what parts of the model should be changed can often be something of an art. It typically reflects your understanding of the assumptions that were made in designing the framework, and also uncertainties and bias present in the input data. For example, the methodology used to gather data used for the calibration might provide hints as to which parameters to change first.\n",
    "\n",
    "In this case, as there are insufficient people, it might be the case that the birth rate was too low. There are two ways to address this\n",
    "\n",
    "- You could go back to the databook and enter a larger value for the birth rate\n",
    "- You can add a 'scale factor' to the parameter set, which scales the parameter value up or down\n",
    "\n",
    "Either approach can be used and would provide equivalent results. Why would we prefer one over the other?\n",
    "\n",
    "Decision factor | Databook calibration | Scale factor calibration\n",
    " ------------ | ------------ | -------------\n",
    "How do you want to adjust the parameter? | Manual adjustment | Automatic adjustment\n",
    "What kinds of parameters is this appropriate for? | Appropriate for model assumptions | Appropriate for original data\n",
    "Granularity of calibration? | Adjustments can vary by year or even timestep | Single scaling factor for all timesteps\n",
    "Pros? | Easy to review reference point for value used in project | Maintains scatter points on plots of the parameter\n",
    "Cons? | Can cause confusion in the databook around what is data and what is not data | Can lack transparency about how parameters are being adjusted without careful review\n",
    "\n",
    "An example of a suitable parameter for databook calibration is `relative seasonality of mosquito population size` - no hard data can exist, but it might be possible to calculate proxy values from other data such as rainfall patterns in different years, adjust annual values manually to match historical epidemic patterns, and then assume a median value for future years. Having this assumption in the databook allows for those calculations to be used as a starting point in the databook before manually editing, and allows for comparability with other projects that use the same parameter. \n",
    "\n",
    "Suggestion: When designing a databook, it is recommended that **all** parameters intended for explicit databook calibration are placed on a single 'Calibration' sheet to provide clarity about what is data and what are calibrated assumptions.\n",
    "\n",
    "An example of a suitable parameter for scale factor calibration is `treatment initiation` used to determine model transitions from diagnosed to treated - a country has reported data for the number of people initiating treatment, and it is important to accurately maintain the official numbers in the databook. Nevertheless, there may be systematic under-reporting by an unknown degree and we want to account for those additional treatments in the model to ensure outcomes are representative, so it is appropriate to adjust the scale factor.\n",
    "\n",
    "An example of a parameter that could be adjusted in either way depending on the circumstances or just personal preferencec would be `force of infection` - this is a clear calibration parameter that is not based on data, and could be adjusted in a databook if it's necessary to reflect changing circumstances external to the model over time, calibrated automatically with a scale factor via the `calibrate` function below in order to achieve the best fit to data, or even a mixture of the two methods.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "The web interfaces (such as the Cascade Analysis Tool) perform calibration using scale factors. The scale factors shown on the website correspond to the values being set here.\n",
    "</div>\n",
    "\n",
    "To set a scale factor, create a `ParameterSet` either by copying an existing one, or creating a new one. Then, access the `pars` attribute to look up the parameter you wish to change, and set the `y_factor` for the population you want to change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = P.parsets[0].copy()\n",
    "p2.pars['b_rate'].y_factor['adults'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example above doubled the birth rate. Now we can run the model again, and see how the results have changed. Notice how the `PlotData` command is being called with both the original results object, and the new results object, allowing both model runs to be shown on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = P.run_sim(parset=p2,result_name = 'More births')\n",
    "d = at.PlotData([result,r2], outputs='sus',project=P)\n",
    "at.plot_series(d,axis='results',data=P.data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have considerably overshot the data, indicating that doubling the birth rate was much too big a change. This would typically be the first step in an iterative process, where you adjust the scale factor, inspect the data, and then make further adjustments. \n",
    "\n",
    "Automated calibration is also available via the project's `calibrate` method. This will automatically adjust parameter values to match the data. To use this function, you need to specify which parameters to set scale factors for, and which variables in the databook to compute calibration quality from. The framework can provide defaults for which parameters to automatically calibrate, or you can pass a list of those parameters in directly. In this example, we will pass in `b_rate` because we want to adjust the birth rate, and we will use `sus` as a measurable since we want to match the number of susceptible people. The configuration therefore corresponds to the example shown above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3 = P.calibrate(max_time=10, parset='default', adjustables=['b_rate'], measurables=['sus']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of automated calibration is another `ParameterSet`. We can inspect the scale factor that the algorithm found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3.pars['b_rate'].y_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can run the model to compare the automated calibration to the original default calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3 = P.run_sim(parset=p3,result_name = 'Auto calibration')\n",
    "d = at.PlotData([result,r3], outputs='sus',project=P)\n",
    "at.plot_series(d,axis='results',data=P.data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration tips\n",
    "\n",
    "While calibrations can vary significantly from model-to-model, some general tips are\n",
    "\n",
    "- Match coarse-grained quantities first, followed by fine-grained quantities. For example, for TB you might calibrate it in the following order:\n",
    "    1. Match population size (adjusting birth rate and death rate)\n",
    "    2. Match disease prevalance (adjusting force of infection)\n",
    "    3. Match drug-resistant/drug-susceptible split (adjusting proportion of infections that are drug-resistant)\n",
    "    \n",
    "For complex models when considering how to proceed with a calibration, it can help to start with mapping the expected relationships between key input parameters that will be used for calibration and key output parameters for which data exists and that should be matched by the calibration, in terms of how changes might flow throughout the model.\n",
    "\n",
    "![t2-calibration-mapping.png](images/t2_calibration_mapping.png)\n",
    "\n",
    "From the diagram above, it can be seen that as is typically the case, population size (`alive`) has a large impact on everything else, but the number of disease-related deaths have only a minor impact on population size in return, so population size needs to be matched first. Incidence (`inci`) and prevalence (`prev`) have a strong cyclical relationship should be considered together, but force of infection and relative likelihood of diagnosis have direct links to modifying each of those individually through changing the rate at which people are infected and changing the rate at which people are diagnosed (and by extension treated). Disease-related deaths (`deaths`) can be considered last if it is not already closely matched from calibrating to prevalence. Because this may adjust the population size, a repeat cycle of calibration may be appropriate to get the best overall fit.\n",
    "\n",
    "A calibration might then proceed in the following order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_par = sc.dcp(P.parsets['default'])\n",
    "for _ in range(3):\n",
    "    cal_par = P.calibrate(max_time=10, parset=cal_par, adjustables=['b_rate', 'other_death'], measurables=['alive'])\n",
    "    cal_par = P.calibrate(max_time=10, parset=cal_par, adjustables=['foi', 'rel_diag'], measurables=['inci', 'prev'])\n",
    "    cal_par = P.calibrate(max_time=10, parset=cal_par, adjustables=['mort_inf'], measurables=['deaths'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:atomica37]",
   "language": "python",
   "name": "conda-env-atomica37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
